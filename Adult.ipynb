{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import grid_search\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import cross_validation\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zteoh\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/adult/adult.data.txt', sep=\", \", header=None, names=['age','workclass','fnlwgt','education','education-num','marital-status',\n",
    "                   'occupation','relationship','race','sex','capital-gain','capital-loss',\n",
    "                   'hours-per-week','native-country',''])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['age','fnlwgt','education-num','capital-gain','capital-loss','native-country','hours-per-week'], axis=1, inplace=True)\n",
    "df = df.replace(to_replace='?', value=np.nan).dropna()\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto encodes any dataframe column of type category or object.\n",
    "def dummyEncode(df):\n",
    "        columnsToEncode = list(df.select_dtypes(include=['category','object']))\n",
    "        le = LabelEncoder()\n",
    "        for feature in columnsToEncode:\n",
    "            try:\n",
    "                df[feature] = le.fit_transform(df[feature])\n",
    "            except:\n",
    "                print('Error encoding '+feature)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dummyEncode(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000L, 7L)\n",
      "(5000L,)\n"
     ]
    }
   ],
   "source": [
    "df = df.as_matrix()\n",
    "X = df[:5000,:7]\n",
    "Y = df[:5000,7]\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_clf_total = []\n",
    "knn_clf_total = []\n",
    "gb_clf_total = []\n",
    "rf_clf_total = []\n",
    "svm_clf_total = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testAllClassifiers(X,Y,train_size):\n",
    "    X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(X, Y, train_size=train_size)\n",
    "\n",
    "    scaling = MinMaxScaler(feature_range=(-1,1)).fit(X_train)\n",
    "    X_train = scaling.transform(X_train)\n",
    "    X_test = scaling.transform(X_test)\n",
    "\n",
    "    k_list = [1]\n",
    "    for i in range (1,26):\n",
    "        k_list.append(i*int(round(train_size*len(X_train)/26)))\n",
    "    print(X_train.shape)\n",
    "\n",
    "    # Logistic Regression\n",
    "    logit_clf = LogisticRegressionCV(solver='newton-cg',Cs=[0.01,0.1,1.0,10.0,100.0])\n",
    "    logit_clf.fit(X_train, Y_train)\n",
    "    logit_clf_total.append(logit_clf.score(X_test, Y_test))\n",
    "\n",
    "    # KNN\n",
    "    knn_params = {\"n_neighbors\":k_list}\n",
    "    clf = KNeighborsClassifier()\n",
    "    knn_clf = grid_search.GridSearchCV(clf, knn_params, cv=3, n_jobs = 8)\n",
    "    knn_clf.fit(X_train,Y_train);\n",
    "    print knn_clf.best_score_\n",
    "    print knn_clf.best_params_\n",
    "    knn_clf_total.append(knn_clf.score(X_test, Y_test))\n",
    "\n",
    "    # Gradient Boosting\n",
    "    gb_params = {\"n_estimators\":[256,512,1024],\n",
    "                \"learning_rate\":[.01,.1]}\n",
    "    clf = GradientBoostingClassifier()\n",
    "    gb_clf = grid_search.GridSearchCV(clf, gb_params, cv=3, n_jobs = 8)\n",
    "    gb_clf.fit(X_train,Y_train);\n",
    "    print gb_clf.best_score_\n",
    "    gb_clf.best_params_\n",
    "    gb_clf_total.append(gb_clf.score(X_test, Y_test))\n",
    "\n",
    "\n",
    "    # Random Forests\n",
    "    rf_params = {\"max_features\":[1,2,3,4,5,6,7],\n",
    "                 \"n_estimators\":[256,512,1024]}\n",
    "    clf = RandomForestClassifier( n_jobs = 4)\n",
    "    rf_clf = grid_search.GridSearchCV(clf, rf_params, cv=3, n_jobs = 8)\n",
    "    rf_clf.fit(X_train,Y_train)\n",
    "    print rf_clf.best_score_\n",
    "    rf_clf.best_params_\n",
    "    rf_clf_total.append(rf_clf.score(X_test, Y_test))\n",
    "\n",
    "\n",
    "    # SVM\n",
    "    svm_params = {'C':[.001,.01,1,10,100]}\n",
    "    clf = svm.SVC(kernel='linear')\n",
    "    svm_clf = grid_search.GridSearchCV(clf, svm_params, cv=3, n_jobs =8)\n",
    "    svm_clf.fit(X_train,Y_train)\n",
    "    print svm_clf.best_score_\n",
    "    svm_clf.best_params_\n",
    "    svm_clf_total.append(svm_clf.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range (0,3):\n",
    "    testAllClassifiers(X,Y,0.2)\n",
    "for i in range (0,3):\n",
    "    testAllClassifiers(X,Y,0.5)\n",
    "for i in range (0,3):\n",
    "    testAllClassifiers(X,Y,0.8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_mean_acc = sum(logit_clf_total)/len(logit_clf_total)\n",
    "knn_mean_acc = sum(knn_clf_total)/len(knn_clf_total)\n",
    "rf_mean_acc = sum(rf_clf_total)/len(rf_clf_total)\n",
    "gb_mean_acc = sum(gb_clf_total)/len(gb_clf_total)\n",
    "svm_mean_acc = sum(svm_clf_total)/len(svm_clf_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.757\n",
      "0.78675\n",
      "0.79625\n",
      "0.82725\n",
      "0.757\n"
     ]
    }
   ],
   "source": [
    "print(logit_mean_acc)\n",
    "print(knn_mean_acc)\n",
    "print(rf_mean_acc)\n",
    "print(gb_mean_acc)\n",
    "print(svm_mean_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
