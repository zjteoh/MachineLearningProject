{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zteoh\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\zteoh\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import grid_search\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import cross_validation\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/bank/bank-full.csv',delimiter=\";\")\n",
    "df = df.replace(to_replace='unknown', value=np.nan).dropna()\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto encodes any dataframe column of type category or object.\n",
    "def dummyEncode(df):\n",
    "        columnsToEncode = list(df.select_dtypes(include=['category','object']))\n",
    "        le = LabelEncoder()\n",
    "        for feature in columnsToEncode:\n",
    "            try:\n",
    "                df[feature] = le.fit_transform(df[feature])\n",
    "            except:\n",
    "                print('Error encoding '+feature)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['age','duration','campaign','pdays','previous','balance','day'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7842L, 10L)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dummyEncode(df)\n",
    "df = df.as_matrix()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7842L, 9L)\n",
      "(7842L,)\n"
     ]
    }
   ],
   "source": [
    "X = df[:,:9]\n",
    "Y = df[:,9]\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_clf_total = []\n",
    "knn_clf_total = []\n",
    "gb_clf_total = []\n",
    "rf_clf_total = []\n",
    "svm_clf_total = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testAllClassifiers(X,Y,train_size):\n",
    "    X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(X, Y, train_size=train_size)\n",
    "\n",
    "    scaling = MinMaxScaler(feature_range=(-1,1)).fit(X_train)\n",
    "    X_train = scaling.transform(X_train)\n",
    "    X_test = scaling.transform(X_test)\n",
    "\n",
    "    k_list = [1]\n",
    "    for i in range (1,26):\n",
    "        k_list.append(i*int(round(train_size*len(X_train)/26)))\n",
    "\n",
    "    # Logistic Regression\n",
    "    logit_clf = LogisticRegressionCV(solver='newton-cg',Cs=[0.01,0.1,1.0,10.0,100.0])\n",
    "    logit_clf.fit(X_train, Y_train)\n",
    "    logit_clf_total.append(logit_clf.score(X_test, Y_test))\n",
    "\n",
    "    # KNN\n",
    "    knn_params = {\"n_neighbors\":k_list}\n",
    "    clf = KNeighborsClassifier()\n",
    "    knn_clf = grid_search.GridSearchCV(clf, knn_params, cv=3, n_jobs = 8)\n",
    "    knn_clf.fit(X_train,Y_train);\n",
    "    print knn_clf.best_score_\n",
    "    print knn_clf.best_params_\n",
    "    knn_clf_total.append(knn_clf.score(X_test, Y_test))\n",
    "\n",
    "    # Gradient Boosting\n",
    "    gb_params = {\"n_estimators\":[256,512,1024],\n",
    "                \"learning_rate\":[.01,.1]}\n",
    "    clf = GradientBoostingClassifier()\n",
    "    gb_clf = grid_search.GridSearchCV(clf, gb_params, cv=3, n_jobs = 8)\n",
    "    gb_clf.fit(X_train,Y_train);\n",
    "    print gb_clf.best_score_\n",
    "    gb_clf.best_params_\n",
    "    gb_clf_total.append(gb_clf.score(X_test, Y_test))\n",
    "\n",
    "\n",
    "    # Random Forests\n",
    "    rf_params = {\"max_features\":[1,2,3,4,5,6,7,8,9],\n",
    "                 \"n_estimators\":[256,512,1024]}\n",
    "    clf = RandomForestClassifier( n_jobs = 4)\n",
    "    rf_clf = grid_search.GridSearchCV(clf, rf_params, cv=3, n_jobs = 8)\n",
    "    rf_clf.fit(X_train,Y_train)\n",
    "    print rf_clf.best_score_\n",
    "    rf_clf.best_params_\n",
    "    rf_clf_total.append(rf_clf.score(X_test, Y_test))\n",
    "\n",
    "\n",
    "    # SVM\n",
    "    svm_params = {'C':[.001,.01,1,10,100]}\n",
    "    clf = svm.SVC(kernel='linear')\n",
    "    svm_clf = grid_search.GridSearchCV(clf, svm_params, cv=3, n_jobs = 8)\n",
    "    svm_clf.fit(X_train,Y_train)\n",
    "    print svm_clf.best_score_\n",
    "    svm_clf.best_params_\n",
    "    svm_clf_total.append(svm_clf.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,3):\n",
    "    testAllClassifiers(X,Y,0.2)\n",
    "for i in range (0,3):\n",
    "    testAllClassifiers(X,Y,0.5)\n",
    "for i in range (0,3):\n",
    "    testAllClassifiers(X,Y,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_mean_acc = sum(logit_clf_total)/len(logit_clf_total)\n",
    "knn_mean_acc = sum(knn_clf_total)/len(knn_clf_total)\n",
    "rf_mean_acc = sum(rf_clf_total)/len(rf_clf_total)\n",
    "gb_mean_acc = sum(gb_clf_total)/len(gb_clf_total)\n",
    "svm_mean_acc = sum(svm_clf_total)/len(svm_clf_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81893528849219\n",
      "0.8205291679948996\n",
      "0.7881734140898948\n",
      "0.8208479438954415\n",
      "0.8233981510997769\n"
     ]
    }
   ],
   "source": [
    "print(logit_mean_acc)\n",
    "print(knn_mean_acc)\n",
    "print(rf_mean_acc)\n",
    "print(gb_mean_acc)\n",
    "print(svm_mean_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
